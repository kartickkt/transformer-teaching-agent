[
  {
    "source": "multi-head attention",
    "target": "self-attention sub-layer",
    "relation": "prerequisite"
  }
]