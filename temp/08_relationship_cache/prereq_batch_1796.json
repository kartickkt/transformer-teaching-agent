[
  {
    "source": "active memory",
    "target": "recurrent attention mechanism",
    "relation": "prerequisite"
  },
  {
    "source": "active memory",
    "target": "attention function",
    "relation": "prerequisite"
  },
  {
    "source": "active memory",
    "target": "attention layers",
    "relation": "prerequisite"
  },
  {
    "source": "active memory",
    "target": "Attention(Q, K, V)",
    "relation": "prerequisite"
  },
  {
    "source": "active memory",
    "target": "additive attention",
    "relation": "prerequisite"
  }
]